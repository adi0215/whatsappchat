{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d97cbe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'UNICODE_EMOJI' from 'emoji' (C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\emoji\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01memoji\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unicode_literals\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01memoji\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNICODE_EMOJI\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m \n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'UNICODE_EMOJI' from 'emoji' (C:\\Users\\Aditya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\emoji\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import regex\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import emoji\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "from emoji import UNICODE_EMOJI\n",
    "\n",
    "from .about import __version__\n",
    "import itertools \n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22c03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rawToDf(file, key):\n",
    "    '''Converts raw .txt file into a Data Frame'''\n",
    "    \n",
    "    split_formats = {\n",
    "        '12hr' : '\\d{1,2}/\\d{1,2}/\\d{2,4},\\s\\d{1,2}:\\d{2}\\s[APap][mM]\\s-\\s',\n",
    "        '24hr' : '\\d{1,2}/\\d{1,2}/\\d{2,4},\\s\\d{1,2}:\\d{2}\\s-\\s',\n",
    "        'custom' : ''\n",
    "    }\n",
    "    datetime_formats = {\n",
    "        '12hr' : '%d/%m/%Y, %I:%M %p - ',\n",
    "        '24hr' : '%d/%m/%Y, %H:%M - ',\n",
    "        'custom': ''\n",
    "    }\n",
    "    \n",
    "    with open(file, 'r', encoding='utf-8') as raw_data:\n",
    "        # print(raw_data.read())\n",
    "        raw_string = ' '.join(raw_data.read().split('\\n')) # converting the list split by newline char. as one whole string as there can be multi-line messages\n",
    "        user_msg = re.split(split_formats[key], raw_string) [1:] # splits at all the date-time pattern, resulting in list of all the messages with user names\n",
    "        date_time = re.findall(split_formats[key], raw_string) # finds all the date-time patterns\n",
    "        \n",
    "        df = pd.DataFrame({'date_time': date_time, 'user_msg': user_msg}) # exporting it to a df\n",
    "        \n",
    "    # converting date-time pattern which is of type String to type datetime,\n",
    "    # format is to be specified for the whole string where the placeholders are extracted by the method \n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], format=datetime_formats[key])\n",
    "    \n",
    "    # split user and msg \n",
    "    usernames = []\n",
    "    msgs = []\n",
    "    for i in df['user_msg']:\n",
    "        a = re.split('([\\w\\W]+?):\\s', i) # lazy pattern match to first {user_name}: pattern and spliting it aka each msg from a user\n",
    "        if(a[1:]): # user typed messages\n",
    "            usernames.append(a[1])\n",
    "            msgs.append(a[2])\n",
    "        else: # other notifications in the group(eg: someone was added, some left ...)\n",
    "            usernames.append(\"group_notification\")\n",
    "            msgs.append(a[0])\n",
    "\n",
    "    # creating new columns         \n",
    "    df['user'] = usernames\n",
    "    df['Message'] = msgs\n",
    "\n",
    "    # dropping the old user_msg col.\n",
    "    df.drop('user_msg', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a5629",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rawToDf('Advika.txt', '12hr')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_messages = df.shape[0]\n",
    "print(total_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_messages = df[df['Message']=='<Media omitted>'].shape[0]\n",
    "print(media_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5bd337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_count(text):\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X',text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "    return emoji_list\n",
    "df['emoji'] = df[\"Message\"].apply(split_count)\n",
    "\n",
    "emojis = sum(df['emoji'].str.len())\n",
    "print(emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba7632",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLPATTERN = r'(https?://\\S+)'\n",
    "df['urlcount'] = df.Message.apply(lambda x: regex.findall(URLPATTERN, x)).str.len()\n",
    "links = np.sum(df.urlcount)\n",
    "\n",
    "print(\"Chats between Aman and Sapna\")\n",
    "print(\"Total Messages: \", total_messages)\n",
    "print(\"Number of Media Shared: \", media_messages)\n",
    "print(\"Number of Emojis Shared\", emojis)\n",
    "print(\"Number of Links Shared\", links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ffa862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
