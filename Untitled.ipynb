{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d97cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import emoji\n",
    "\n",
    "import itertools \n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22c03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rawToDf(file, key):\n",
    "    '''Converts raw .txt file into a Data Frame'''\n",
    "    \n",
    "    split_formats = {\n",
    "        '12hr' : '\\d{1,2}/\\d{1,2}/\\d{2,4},\\s\\d{1,2}:\\d{2}\\s[APap][mM]\\s-\\s',\n",
    "        '24hr' : '\\d{1,2}/\\d{1,2}/\\d{2,4},\\s\\d{1,2}:\\d{2}\\s-\\s',\n",
    "        'custom' : ''\n",
    "    }\n",
    "    datetime_formats = {\n",
    "        '12hr' : '%d/%m/%Y, %I:%M %p - ',\n",
    "        '24hr' : '%d/%m/%Y, %H:%M - ',\n",
    "        'custom': ''\n",
    "    }\n",
    "    \n",
    "    with open(file, 'r', encoding='utf-8') as raw_data:\n",
    "        # print(raw_data.read())\n",
    "        raw_string = ' '.join(raw_data.read().split('\\n')) # converting the list split by newline char. as one whole string as there can be multi-line messages\n",
    "        user_msg = re.split(split_formats[key], raw_string) [1:] # splits at all the date-time pattern, resulting in list of all the messages with user names\n",
    "        date_time = re.findall(split_formats[key], raw_string) # finds all the date-time patterns\n",
    "        \n",
    "        df = pd.DataFrame({'date_time': date_time, 'user_msg': user_msg}) # exporting it to a df\n",
    "        \n",
    "    # converting date-time pattern which is of type String to type datetime,\n",
    "    # format is to be specified for the whole string where the placeholders are extracted by the method \n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], format=datetime_formats[key])\n",
    "    \n",
    "    # split user and msg \n",
    "    usernames = []\n",
    "    msgs = []\n",
    "    for i in df['user_msg']:\n",
    "        a = re.split('([\\w\\W]+?):\\s', i) # lazy pattern match to first {user_name}: pattern and spliting it aka each msg from a user\n",
    "        if(a[1:]): # user typed messages\n",
    "            usernames.append(a[1])\n",
    "            msgs.append(a[2])\n",
    "        else: # other notifications in the group(eg: someone was added, some left ...)\n",
    "            usernames.append(\"group_notification\")\n",
    "            msgs.append(a[0])\n",
    "\n",
    "    # creating new columns         \n",
    "    df['user'] = usernames\n",
    "    df['Message'] = msgs\n",
    "\n",
    "    # dropping the old user_msg col.\n",
    "    df.drop('user_msg', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343a5629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>user</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-09 16:32:00</td>\n",
       "      <td>group_notification</td>\n",
       "      <td>Messages and calls are end-to-end encrypted. N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-09 16:32:00</td>\n",
       "      <td>group_notification</td>\n",
       "      <td>Your security code with Advika changed. Tap to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-21 21:57:00</td>\n",
       "      <td>group_notification</td>\n",
       "      <td>Your security code with Advika changed. Tap to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-27 15:07:00</td>\n",
       "      <td>group_notification</td>\n",
       "      <td>Your security code with Advika changed. Tap to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-13 21:19:00</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>2023-04-06 16:41:00</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>Yea it doesn't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>2023-04-06 16:41:00</td>\n",
       "      <td>Advika</td>\n",
       "      <td>Yea only NLP for sentiment analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>2023-04-06 16:42:00</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>See it's doing few thing no like sentiment ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>2023-04-06 16:43:00</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>So we can tell her we have done for like predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>2023-04-06 16:43:00</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>Btw it doesn't uses any ml model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2366 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date_time                user  \\\n",
       "0    2021-12-09 16:32:00  group_notification   \n",
       "1    2021-12-09 16:32:00  group_notification   \n",
       "2    2022-01-21 21:57:00  group_notification   \n",
       "3    2022-01-27 15:07:00  group_notification   \n",
       "4    2022-09-13 21:19:00              Aditya   \n",
       "...                  ...                 ...   \n",
       "2361 2023-04-06 16:41:00              Aditya   \n",
       "2362 2023-04-06 16:41:00              Advika   \n",
       "2363 2023-04-06 16:42:00              Aditya   \n",
       "2364 2023-04-06 16:43:00              Aditya   \n",
       "2365 2023-04-06 16:43:00              Aditya   \n",
       "\n",
       "                                                Message  \n",
       "0     Messages and calls are end-to-end encrypted. N...  \n",
       "1     Your security code with Advika changed. Tap to...  \n",
       "2     Your security code with Advika changed. Tap to...  \n",
       "3     Your security code with Advika changed. Tap to...  \n",
       "4                                      <Media omitted>   \n",
       "...                                                 ...  \n",
       "2361                                    Yea it doesn't   \n",
       "2362               Yea only NLP for sentiment analysis   \n",
       "2363  See it's doing few thing no like sentiment ana...  \n",
       "2364  So we can tell her we have done for like predi...  \n",
       "2365                  Btw it doesn't uses any ml model   \n",
       "\n",
       "[2366 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = rawToDf('Advika.txt', '12hr')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6dc0317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2366\n"
     ]
    }
   ],
   "source": [
    "total_messages = df.shape[0]\n",
    "print(total_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511f2f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "media_messages = df[df['Message']=='<Media omitted>'].shape[0]\n",
    "print(media_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5bd337",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m             emoji_list\u001b[38;5;241m.\u001b[39mappend(word)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m emoji_list\n\u001b[1;32m----> 8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoji\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMessage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_count\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m emojis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoji\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlen())\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(emojis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36msplit_count\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_count\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     emoji_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mregex\u001b[49m\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m,text)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(char \u001b[38;5;129;01min\u001b[39;00m emoji\u001b[38;5;241m.\u001b[39mUNICODE_EMOJI \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m word):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'regex' is not defined"
     ]
    }
   ],
   "source": [
    "def split_count(text):\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X',text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "    return emoji_list\n",
    "df['emoji'] = df[\"Message\"].apply(split_count)\n",
    "\n",
    "emojis = sum(df['emoji'].str.len())\n",
    "print(emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba7632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3575f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
