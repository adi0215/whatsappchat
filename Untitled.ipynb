{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d97cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import emoji\n",
    "\n",
    "import itertools \n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22c03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rawToDf(file, key):\n",
    "    '''Converts raw .txt file into a Data Frame'''\n",
    "    \n",
    "    split_formats = {\n",
    "        '12hr' : '\\d{1,2}/\\d{1,2}/\\d{2,4},\\s\\d{1,2}:\\d{2}\\s[APap][mM]\\s-\\s',\n",
    "        '24hr' : '\\d{1,2}/\\d{1,2}/\\d{2,4},\\s\\d{1,2}:\\d{2}\\s-\\s',\n",
    "        'custom' : ''\n",
    "    }\n",
    "    datetime_formats = {\n",
    "        '12hr' : '%d/%m/%Y, %I:%M %p - ',\n",
    "        '24hr' : '%d/%m/%Y, %H:%M - ',\n",
    "        'custom': ''\n",
    "    }\n",
    "    \n",
    "    with open(file, 'r', encoding='utf-8') as raw_data:\n",
    "        # print(raw_data.read())\n",
    "        raw_string = ' '.join(raw_data.read().split('\\n')) # converting the list split by newline char. as one whole string as there can be multi-line messages\n",
    "        user_msg = re.split(split_formats[key], raw_string) [1:] # splits at all the date-time pattern, resulting in list of all the messages with user names\n",
    "        date_time = re.findall(split_formats[key], raw_string) # finds all the date-time patterns\n",
    "        \n",
    "        df = pd.DataFrame({'date_time': date_time, 'user_msg': user_msg}) # exporting it to a df\n",
    "        \n",
    "    # converting date-time pattern which is of type String to type datetime,\n",
    "    # format is to be specified for the whole string where the placeholders are extracted by the method \n",
    "    df['date_time'] = pd.to_datetime(df['date_time'], format=datetime_formats[key])\n",
    "    \n",
    "    # split user and msg \n",
    "    usernames = []\n",
    "    msgs = []\n",
    "    for i in df['user_msg']:\n",
    "        a = re.split('([\\w\\W]+?):\\s', i) # lazy pattern match to first {user_name}: pattern and spliting it aka each msg from a user\n",
    "        if(a[1:]): # user typed messages\n",
    "            usernames.append(a[1])\n",
    "            msgs.append(a[2])\n",
    "        else: # other notifications in the group(eg: someone was added, some left ...)\n",
    "            usernames.append(\"group_notification\")\n",
    "            msgs.append(a[0])\n",
    "\n",
    "    # creating new columns         \n",
    "    df['user'] = usernames\n",
    "    df['Message'] = msgs\n",
    "\n",
    "    # dropping the old user_msg col.\n",
    "    df.drop('user_msg', axis=1, inplace=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343a5629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>user</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-09 16:32:00</td>\n",
       "      <td>group_notification</td>\n",
       "      <td>Messages and calls are end-to-end encrypted. N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-09 16:32:00</td>\n",
       "      <td>group_notification</td>\n",
       "      <td>Your security code with Advika changed. Tap to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-21 21:57:00</td>\n",
       "      <td>group_notification</td>\n",
       "      <td>Your security code with Advika changed. Tap to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-27 15:07:00</td>\n",
       "      <td>group_notification</td>\n",
       "      <td>Your security code with Advika changed. Tap to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-13 21:19:00</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>&lt;Media omitted&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>2023-04-06 16:41:00</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>Yea it doesn't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>2023-04-06 16:41:00</td>\n",
       "      <td>Advika</td>\n",
       "      <td>Yea only NLP for sentiment analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>2023-04-06 16:42:00</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>See it's doing few thing no like sentiment ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>2023-04-06 16:43:00</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>So we can tell her we have done for like predi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "      <td>2023-04-06 16:43:00</td>\n",
       "      <td>Aditya</td>\n",
       "      <td>Btw it doesn't uses any ml model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2366 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date_time                user  \\\n",
       "0    2021-12-09 16:32:00  group_notification   \n",
       "1    2021-12-09 16:32:00  group_notification   \n",
       "2    2022-01-21 21:57:00  group_notification   \n",
       "3    2022-01-27 15:07:00  group_notification   \n",
       "4    2022-09-13 21:19:00              Aditya   \n",
       "...                  ...                 ...   \n",
       "2361 2023-04-06 16:41:00              Aditya   \n",
       "2362 2023-04-06 16:41:00              Advika   \n",
       "2363 2023-04-06 16:42:00              Aditya   \n",
       "2364 2023-04-06 16:43:00              Aditya   \n",
       "2365 2023-04-06 16:43:00              Aditya   \n",
       "\n",
       "                                                Message  \n",
       "0     Messages and calls are end-to-end encrypted. N...  \n",
       "1     Your security code with Advika changed. Tap to...  \n",
       "2     Your security code with Advika changed. Tap to...  \n",
       "3     Your security code with Advika changed. Tap to...  \n",
       "4                                      <Media omitted>   \n",
       "...                                                 ...  \n",
       "2361                                    Yea it doesn't   \n",
       "2362               Yea only NLP for sentiment analysis   \n",
       "2363  See it's doing few thing no like sentiment ana...  \n",
       "2364  So we can tell her we have done for like predi...  \n",
       "2365                  Btw it doesn't uses any ml model   \n",
       "\n",
       "[2366 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = rawToDf('Advika.txt', '12hr')\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6dc0317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2366\n"
     ]
    }
   ],
   "source": [
    "total_messages = df.shape[0]\n",
    "print(total_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511f2f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "media_messages = df[df['Message']=='<Media omitted>'].shape[0]\n",
    "print(media_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f5bd337",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m             emoji_list\u001b[38;5;241m.\u001b[39mappend(word)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m emoji_list\n\u001b[1;32m----> 9\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoji\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[43msplit_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMessage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m emojis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memoji\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlen())\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(emojis)\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36msplit_count\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_count\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     emoji_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mregex\u001b[49m\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m'\u001b[39m,text)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(char \u001b[38;5;129;01min\u001b[39;00m emoji\u001b[38;5;241m.\u001b[39mUNICODE_EMOJI \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m word):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'regex' is not defined"
     ]
    }
   ],
   "source": [
    "def split_count(text):\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X',text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "    return emoji_list\n",
    "\n",
    "df['emoji'] = df[\"Message\"].apply(split_count(df[\"Message\"]))\n",
    "\n",
    "emojis = sum(df['emoji'].str.len())\n",
    "print(emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebba7632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3575f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
